{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_IMDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWXtwGk+2IHLTVT5hR0C4H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArshockAbedan/ML2021/blob/main/Keras_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqLvxaGKWzIW"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.datasets as datasets\n",
        "import tensorflow.keras.layers as layers\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Xo1IB8FXMZy",
        "outputId": "45b3f5e7-fa48-41b5-bb9f-1d89e8205dc8"
      },
      "source": [
        "# Load the IMDB mvie review dataset\n",
        "data = datasets.imdb.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haZRIQNhXi5Q"
      },
      "source": [
        "# Similar to MNIST dataset, it split between training and testing data \n",
        "(x_train, y_train), (x_test, y_test) = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTM7V1N6YAw5"
      },
      "source": [
        "# Load the worw_index table\n",
        "index = datasets.imdb.get_word_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "438IXMEBYJoo"
      },
      "source": [
        "# build the lookup table\n",
        "id_to_word = dict((i+3, w) for (w, i) in index.items())\n",
        "id_to_word.update({\n",
        "    0: '<PAD>',\n",
        "    1: '<START>',\n",
        "    2: '<UNKOWN>',\n",
        "    3: '<UNUSED>',\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9HtUvRVY3tD",
        "outputId": "bc1a6920-0626-472b-8e98-ddb17ff7cc99"
      },
      "source": [
        "np.array(x_train[0][:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,   14,   22,   16,   43,  530,  973, 1622, 1385,   65])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IVFUVgznZE2R",
        "outputId": "60883851-6eb3-431a-a312-e2878af0e4c4"
      },
      "source": [
        "# decode the above sequence\n",
        "\" \".join(id_to_word[i] for i in x_train[0][:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<START> this film was just brilliant casting location scenery story'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcDw7F9BZi5g"
      },
      "source": [
        "def decode(ordinals):\n",
        "  return \" \".join(id_to_word[i] for i in ordinals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO84TTGpZw0Y",
        "outputId": "af8f6e07-ed98-4dae-daee-53b28f780f6b"
      },
      "source": [
        "decode(x_train[2]), y_train[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"<START> this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had earnt working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how embarrasing this is to watch save yourself an hour a bit of your life\",\n",
              " 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlWpb5BLZakY",
        "outputId": "18056dbf-7ac2-4781-e3fb-94f5b4642a87"
      },
      "source": [
        "# The vocabulary size is\n",
        "len(index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88584"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1-YgazBaGzL"
      },
      "source": [
        "**A Reduced Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORIeeI7GZ2Ew",
        "outputId": "7f2f790b-1e6e-42d5-aef4-5ee2cbfbe238"
      },
      "source": [
        "data = datasets.imdb.load_data(\n",
        "    num_words = 1000,\n",
        "    skip_top = 5\n",
        ")\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "wo07gaydaWUr",
        "outputId": "9e1d65c4-804f-484b-a61f-af0cc39896b2"
      },
      "source": [
        "decode(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<UNKOWN> this film was just brilliant casting <UNKOWN> <UNKOWN> story direction <UNKOWN> really <UNKOWN> <UNKOWN> part they played and you could just imagine being there robert <UNKOWN> is an amazing actor and now <UNKOWN> same being director <UNKOWN> father came from <UNKOWN> same <UNKOWN> <UNKOWN> as myself so i loved <UNKOWN> fact there was a real <UNKOWN> with this film <UNKOWN> <UNKOWN> <UNKOWN> throughout <UNKOWN> film were great it was just brilliant so much that i <UNKOWN> <UNKOWN> film as soon as it was released for <UNKOWN> and would recommend it to everyone to watch and <UNKOWN> <UNKOWN> <UNKOWN> was amazing really <UNKOWN> at <UNKOWN> end it was so sad and you know what they say if you <UNKOWN> at a film it must have been good and this definitely was also <UNKOWN> to <UNKOWN> two little <UNKOWN> that played <UNKOWN> <UNKOWN> of <UNKOWN> and paul they were just brilliant children are often left out of <UNKOWN> <UNKOWN> <UNKOWN> i think because <UNKOWN> stars that play them all <UNKOWN> up are such a big <UNKOWN> for <UNKOWN> whole film but these children are amazing and should be <UNKOWN> for what they have done don't you think <UNKOWN> whole story was so <UNKOWN> because it was true and was <UNKOWN> life after all that was <UNKOWN> with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "L27oebddaodR",
        "outputId": "c229a7e0-151e-4719-b969-a46456ac4ce8"
      },
      "source": [
        "decode(x_train[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<UNKOWN> big <UNKOWN> big <UNKOWN> bad music and a <UNKOWN> <UNKOWN> <UNKOWN> these are <UNKOWN> words to best <UNKOWN> this terrible movie i love cheesy horror movies and i've seen <UNKOWN> but this had got to be on of <UNKOWN> worst ever made <UNKOWN> plot is <UNKOWN> <UNKOWN> and ridiculous <UNKOWN> acting is an <UNKOWN> <UNKOWN> script is completely <UNKOWN> <UNKOWN> best is <UNKOWN> end <UNKOWN> with <UNKOWN> <UNKOWN> and how he worked out who <UNKOWN> killer is it's just so <UNKOWN> <UNKOWN> written <UNKOWN> <UNKOWN> are <UNKOWN> and funny in <UNKOWN> <UNKOWN> <UNKOWN> <UNKOWN> is big lots of <UNKOWN> <UNKOWN> men <UNKOWN> those cut <UNKOWN> <UNKOWN> that show off their <UNKOWN> <UNKOWN> that men actually <UNKOWN> them and <UNKOWN> music is just <UNKOWN> <UNKOWN> that plays over and over again in almost every scene there is <UNKOWN> music <UNKOWN> and <UNKOWN> taking away <UNKOWN> and <UNKOWN> <UNKOWN> still doesn't close for <UNKOWN> all <UNKOWN> <UNKOWN> this is a truly bad film whose only <UNKOWN> is to look back on <UNKOWN> <UNKOWN> that was <UNKOWN> <UNKOWN> and have a good old laugh at how bad everything was back then\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxQA3RGYasZg"
      },
      "source": [
        "# encode text to ordinals (at the application level), I compute the reserve lookup table\n",
        "word_to_id = {\n",
        "    w:i for (i,w) in id_to_word.items()\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUESwLuEbMNp"
      },
      "source": [
        "def encode(text):\n",
        "  return [word_to_id.get(w, 2) for w in text.split()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C6E9FIVbg1C",
        "outputId": "ba8a7cc9-7f1a-4f8c-d257-582c862573c9"
      },
      "source": [
        "encode(\"this film was just brilliant casting\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14, 22, 16, 43, 530, 973]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y03B_vjjonDU"
      },
      "source": [
        "**End-to-end Text Classification with RNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC_moQ19bkwg"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.datasets as datasets\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.preprocessing.sequence as sequence\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ1supoRn6jW",
        "outputId": "a771bd6d-ca4a-46fb-9428-f2cb26eb39c8"
      },
      "source": [
        "data = datasets.imdb.load_data(num_words=10000, skip_top=10)\n",
        "word_index = datasets.imdb.get_word_index()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydI_MQkpqJry"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = data"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lijBTBiZpqoQ"
      },
      "source": [
        "i2w = dict((i+3,w) for (w,i) in word_index.items())\n",
        "i2w.update({\n",
        "    0: '<PAD>',\n",
        "    1: '<START>',\n",
        "    2: '<OOV>',\n",
        "    3: '<?>',\n",
        "})"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VblfyVHYqd0e"
      },
      "source": [
        "# The ordinal2text function decodes the ordinal numbers to text\n",
        "def ordinal2text(seq):\n",
        "  return \" \".join([i2w[i] for i in seq])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "OKxazEL5qu4-",
        "outputId": "d04bcb4c-e8bd-4f80-9e87-a27da7f02338"
      },
      "source": [
        "ordinal2text(x_train[0])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<OOV> this film was just brilliant casting location scenery story direction everyone's really suited <OOV> part they played <OOV> you could just imagine being there robert <OOV> <OOV> an amazing actor <OOV> now <OOV> same being director <OOV> father came from <OOV> same scottish island as myself so i loved <OOV> fact there was <OOV> real connection with this film <OOV> witty remarks throughout <OOV> film were great it was just brilliant so much that i bought <OOV> film as soon as it was released for <OOV> <OOV> would recommend it <OOV> everyone <OOV> watch <OOV> <OOV> fly fishing was amazing really cried at <OOV> end it was so sad <OOV> you know what they say if you cry at <OOV> film it must have been good <OOV> this definitely was also <OOV> <OOV> <OOV> two little boy's that played <OOV> <OOV> <OOV> norman <OOV> paul they were just brilliant children are often left out <OOV> <OOV> <OOV> list i think because <OOV> stars that play them all grown up are such <OOV> big profile for <OOV> whole film but these children are amazing <OOV> should be praised for what they have done don't you think <OOV> whole story was so lovely because it was true <OOV> was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn1g67bDqy5u"
      },
      "source": [
        "# The embedding layer maps ordinal indices to embedding vectors.\n",
        "# Input shape is:  (batch_size, sequence_length)\n",
        "# Output shape is: (batch_size, sequence_length, dimension)\n",
        "embedding = layers.Embedding(10000, 20)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40U3OFu3rNbe",
        "outputId": "8ed5776e-4b92-42bf-c58b-46b7f5caf8ab"
      },
      "source": [
        "input_seq = np.array([[1,2,3, 3, 2], [1,2, 0, 0, 0]])\n",
        "\n",
        "embedding_vectors = embedding(input_seq)\n",
        "\n",
        "print(input_seq.shape,\"==>\", embedding_vectors.shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 5) ==> (2, 5, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJKzKjH0ryLe"
      },
      "source": [
        "# The SimpleRNN layer uses state vectors - embedding_vectors - to perform reduction on the sequence of input vectors.\n",
        "rnn = layers.SimpleRNN(7)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWDBuQ-AsOQ_",
        "outputId": "74bba43e-77cf-4418-86bc-6febdf3618ec"
      },
      "source": [
        "output_vector = rnn(embedding_vectors)\n",
        "\n",
        "print(embedding_vectors.shape, \"==>\", output_vector.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 5, 20) ==> (2, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PV_lByQsbGo"
      },
      "source": [
        "# We can use a dense layer to conver the RNN output to a probability of good movie review\n",
        "dense = layers.Dense(1, activation='sigmoid')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8vmpJqgsniw",
        "outputId": "b6ac6618-0a27-4569-eaf6-a8cc8faecefc"
      },
      "source": [
        "output = dense(output_vector)\n",
        "\n",
        "print(output_vector.shape, \"==>\", output.shape)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 7) ==> (2, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEPSHLHts214"
      },
      "source": [
        "**Padding and truncation**\n",
        "\n",
        "We need all the input sequences to have the same length for embedding layer to work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9cNToygsx6n",
        "outputId": "aff50d39-fa0a-46b0-88b5-7654bb24adc1"
      },
      "source": [
        "batch = x_train[:5]\n",
        "\n",
        "[len(x) for x in batch]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[218, 189, 141, 550, 147]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq-641CftZJ8"
      },
      "source": [
        "This requires us to padd all the sequences that are too short, and truncate sequences that are too long"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITFy7VHktRGR",
        "outputId": "ab28ffc9-d9c8-4d5c-e54e-e7df9d95fc6a"
      },
      "source": [
        "padded_batch = sequence.pad_sequences(batch, maxlen=200)\n",
        "\n",
        "[len(x) for x in padded_batch]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[200, 200, 200, 200, 200]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABJVssWVtuxK",
        "outputId": "eef8808c-3050-4912-bf66-d121ded4d903"
      },
      "source": [
        "padded_batch"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   2,   25,  100,   43,  838,  112,   50,  670,    2,    2,   35,\n",
              "         480,  284,    2,  150,    2,  172,  112,  167,    2,  336,  385,\n",
              "          39,    2,  172, 4536, 1111,   17,  546,   38,   13,  447,    2,\n",
              "         192,   50,   16,    2,  147, 2025,   19,   14,   22,    2, 1920,\n",
              "        4613,  469,    2,   22,   71,   87,   12,   16,   43,  530,   38,\n",
              "          76,   15,   13, 1247,    2,   22,   17,  515,   17,   12,   16,\n",
              "         626,   18,    2,    2,   62,  386,   12,    2,  316,    2,  106,\n",
              "           2,    2, 2223, 5244,   16,  480,   66, 3785,   33,    2,  130,\n",
              "          12,   16,   38,  619,    2,   25,  124,   51,   36,  135,   48,\n",
              "          25, 1415,   33,    2,   22,   12,  215,   28,   77,   52,    2,\n",
              "          14,  407,   16,   82,    2,    2,    2,  107,  117, 5952,   15,\n",
              "         256,    2,    2,    2, 3766,    2,  723,   36,   71,   43,  530,\n",
              "         476,   26,  400,  317,   46,    2,    2,    2, 1029,   13,  104,\n",
              "          88,    2,  381,   15,  297,   98,   32, 2071,   56,   26,  141,\n",
              "           2,  194, 7486,   18,    2,  226,   22,   21,  134,  476,   26,\n",
              "         480,    2,  144,   30, 5535,   18,   51,   36,   28,  224,   92,\n",
              "          25,  104,    2,  226,   65,   16,   38, 1334,   88,   12,   16,\n",
              "         283,    2,   16, 4472,  113,  103,   32,   15,   16, 5345,   19,\n",
              "         178,   32],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           2,  194, 1153,  194, 8255,   78,  228,    2,    2, 1463, 4369,\n",
              "        5012,  134,   26,    2,  715,    2,  118, 1634,   14,  394,   20,\n",
              "          13,  119,  954,  189,  102,    2,  207,  110, 3103,   21,   14,\n",
              "          69,  188,    2,   30,   23,    2,    2,  249,  126,   93,    2,\n",
              "         114,    2, 2300, 1523,    2,  647,    2,  116,    2,   35, 8163,\n",
              "           2,  229,    2,  340, 1322,    2,  118,    2,    2,  130, 4901,\n",
              "          19,    2, 1002,    2,   89,   29,  952,   46,   37,    2,  455,\n",
              "           2,   45,   43,   38, 1543, 1905,  398,    2, 1649,   26, 6853,\n",
              "           2,  163,   11, 3215,    2,    2, 1153,    2,  194,  775,    2,\n",
              "        8255,    2,  349, 2637,  148,  605,    2, 8003,   15,  123,  125,\n",
              "          68,    2, 6853,   15,  349,  165, 4362,   98,    2,    2,  228,\n",
              "           2,   43,    2, 1157,   15,  299,  120,    2,  120,  174,   11,\n",
              "         220,  175,  136,   50,    2, 4373,  228, 8255,    2,    2,  656,\n",
              "         245, 2350,    2,    2, 9837,  131,  152,  491,   18,    2,   32,\n",
              "        7464, 1212,   14,    2,    2,  371,   78,   22,  625,   64, 1382,\n",
              "           2,    2,  168,  145,   23,    2, 1690,   15,   16,    2, 1355,\n",
              "           2,   28,    2,   52,  154,  462,   33,   89,   78,  285,   16,\n",
              "         145,   95],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    2,   14,   47,    2,   30,   31,    2,\n",
              "           2,  249,  108,    2,    2, 5974,   54,   61,  369,   13,   71,\n",
              "         149,   14,   22,  112,    2, 2401,  311,   12,   16, 3711,   33,\n",
              "          75,   43, 1829,  296,    2,   86,  320,   35,  534,   19,  263,\n",
              "        4821, 1301,    2, 1873,   33,   89,   78,   12,   66,   16,    2,\n",
              "         360,    2,    2,   58,  316,  334,   11,    2, 1716,   43,  645,\n",
              "         662,    2,  257,   85, 1200,   42, 1228, 2578,   83,   68, 3912,\n",
              "          15,   36,  165, 1539,  278,   36,   69,    2,  780,    2,  106,\n",
              "          14, 6905, 1338,   18,    2,   22,   12,  215,   28,  610,   40,\n",
              "           2,   87,  326,   23, 2300,   21,   23,   22,   12,  272,   40,\n",
              "          57,   31,   11,    2,   22,   47,    2, 2307,   51,    2,  170,\n",
              "          23,  595,  116,  595, 1352,   13,  191,   79,  638,   89,    2,\n",
              "          14,    2,    2,  106,  607,  624,   35,  534,    2,  227,    2,\n",
              "         129,  113],\n",
              "       [   2,  341,    2,   27,  846,   10,   10,   29,    2, 1906,    2,\n",
              "          97,    2,  236,    2, 1311,    2,    2,    2,    2,   31,    2,\n",
              "           2,   91,    2, 3987,   70,    2,  882,   30,  579,   42,    2,\n",
              "          12,   32,   11,  537,   10,   10,   11,   14,   65,   44,  537,\n",
              "          75,    2, 1775, 3353,    2, 1846,    2,    2,    2,  154,    2,\n",
              "           2,  518,   53,    2,    2,    2, 3211,  882,   11,  399,   38,\n",
              "          75,  257, 3807,   19,    2,   17,   29,  456,    2,   65,    2,\n",
              "          27,  205,  113,   10,   10,    2,    2,    2,    2,    2,  242,\n",
              "           2,   91, 1202,    2,    2, 2070,  307,   22,    2, 5168,  126,\n",
              "          93,   40,    2,   13,  188, 1076, 3222,   19,    2,    2,    2,\n",
              "        2348,  537,   23,   53,  537,   21,   82,   40,    2,   13,    2,\n",
              "          14,  280,   13,  219,    2,    2,  431,  758,  859,    2,  953,\n",
              "        1052,    2,    2, 5991,    2,   94,   40,   25,  238,   60,    2,\n",
              "           2,    2,  804,    2,    2,    2, 9941,  132,    2,   67,    2,\n",
              "          22,   15,    2,  283,    2, 5168,   14,   31,    2,  242,  955,\n",
              "          48,   25,  279,    2,   23,   12, 1685,  195,   25,  238,   60,\n",
              "         796,    2,    2,  671,    2, 2804,    2,    2,  559,  154,  888,\n",
              "           2,  726,   50,   26,   49, 7008,   15,  566,   30,  579,   21,\n",
              "          64, 2574],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    2,  249,\n",
              "        1323,    2,   61,  113,   10,   10,   13, 1637,   14,   20,   56,\n",
              "          33, 2401,   18,  457,   88,   13, 2626, 1400,   45, 3171,   13,\n",
              "          70,   79,   49,  706,  919,   13,   16,  355,  340,  355, 1696,\n",
              "          96,  143,    2,   22,   32,  289,    2,   61,  369,   71, 2359,\n",
              "           2,   13,   16,  131, 2073,  249,  114,  249,  229,  249,   20,\n",
              "          13,   28,  126,  110,   13,  473,    2,  569,   61,  419,   56,\n",
              "         429,    2, 1513,   18,   35,  534,   95,  474,  570,    2,   25,\n",
              "         124,  138,   88,   12,  421, 1543,   52,  725, 6397,   61,  419,\n",
              "          11,   13, 1571,   15, 1543,   20,   11,    2,    2,    2,  296,\n",
              "          12, 3524,    2,   15,  421,  128,   74,  233,  334,  207,  126,\n",
              "         224,   12,  562,  298, 2167, 1272,    2, 2601,    2,  516,  988,\n",
              "          43,    2,   79,  120,   15,  595,   13,  784,   25, 3171,   18,\n",
              "         165,  170,  143,   19,   14,    2, 7224,    2,  226,  251,    2,\n",
              "          61,  113]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2sxNrxQt1gg"
      },
      "source": [
        "**Building an end-to-end network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOYDMbnktws4"
      },
      "source": [
        "maxlen = 200\n",
        "inputs = layers.Input(shape=(maxlen))\n",
        "x = embedding(inputs)\n",
        "x = rnn(x)\n",
        "sentiment_output = dense(x)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhYKK7ytuSvq"
      },
      "source": [
        "model = models.Model(inputs=inputs, outputs = sentiment_output)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "asgsYfS2ug9J",
        "outputId": "ad675612-c10c-4698-cb43-76b0a08f2927"
      },
      "source": [
        "keras.utils.plot_model(model)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xQ_RpTculXh"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoXVTtjVu2pR"
      },
      "source": [
        "x_train_padded = sequence.pad_sequences(x_train, maxlen=maxlen)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4EuWJL2vCKR",
        "outputId": "bbea0cb9-3f83-42ea-f0b1-b1c93cefe203"
      },
      "source": [
        "model.fit(x_train_padded, y_train, epochs=5, validation_split=0.2)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 20s 31ms/step - loss: 0.6720 - acc: 0.5586 - val_loss: 0.5101 - val_acc: 0.7584\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 0.4006 - acc: 0.8250 - val_loss: 0.3985 - val_acc: 0.8312\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 0.2752 - acc: 0.8959 - val_loss: 0.3993 - val_acc: 0.8236\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 0.2144 - acc: 0.9233 - val_loss: 0.4183 - val_acc: 0.8266\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 0.1696 - acc: 0.9442 - val_loss: 0.4494 - val_acc: 0.8332\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0aec6e7b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZeBBbznvfCl"
      },
      "source": [
        "We can make use of the model to do some text analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvsC7Fq8vUg9"
      },
      "source": [
        "w2i = {w:i for (i,w) in i2w.items()}\n",
        "\n",
        "def text2ordinal(text):\n",
        "    return [w2i.get(w, 2) for w in text.split()]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ27HgULwHM_",
        "outputId": "2c89d9db-912a-48eb-bf4c-0fdc8aa097a1"
      },
      "source": [
        "text_ordinals = text2ordinal(\"This film was just brilliant\")\n",
        "model.predict(sequence.pad_sequences([text_ordinals], maxlen=maxlen))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9714042]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6hfYcWewcHg",
        "outputId": "1a8a082e-5e16-4d37-d09a-eb7431e09af2"
      },
      "source": [
        "text_ordinals = text2ordinal(\"rendered terrible flat flat flat performances\")\n",
        "model.predict(sequence.pad_sequences([text_ordinals], maxlen=maxlen))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.28292137]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D68hWO5Zwpnu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}