{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_RNN_text_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOkHWWo2xj4aClUMBzP+XUL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArshockAbedan/ML2021/blob/main/NLP_RNN_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPiacx_8gNuz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "# import os\n",
        "# os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
        "\n",
        "\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZAK4ySZwgVdp",
        "outputId": "6147b68f-b554-499a-a58f-6e5f73eeb92b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, info = tfds.load('imdb_reviews', data_dir='.', with_info=True, as_supervised=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XashmXewgiU5",
        "outputId": "86548c3a-cde8-4b45-e3b7-a02d7614af93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to ./imdb_reviews/plain_text/1.0.0...\u001b[0m\n",
            "Shuffling and writing examples to ./imdb_reviews/plain_text/1.0.0.incompleteY6KRRR/imdb_reviews-train.tfrecord\n",
            "Shuffling and writing examples to ./imdb_reviews/plain_text/1.0.0.incompleteY6KRRR/imdb_reviews-test.tfrecord\n",
            "Shuffling and writing examples to ./imdb_reviews/plain_text/1.0.0.incompleteY6KRRR/imdb_reviews-unsupervised.tfrecord\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDataset imdb_reviews downloaded and prepared to ./imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeuJU1UPgkoN",
        "outputId": "2ac31067-59a5-4662-ed95-4a9fe7b9cd04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='imdb_reviews',\n",
              "    version=1.0.0,\n",
              "    description='Large Movie Review Dataset.\n",
              "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
              "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
              "    features=FeaturesDict({\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
              "        'text': Text(shape=(), dtype=tf.string),\n",
              "    }),\n",
              "    total_num_examples=100000,\n",
              "    splits={\n",
              "        'test': 25000,\n",
              "        'train': 25000,\n",
              "        'unsupervised': 50000,\n",
              "    },\n",
              "    supervised_keys=('text', 'label'),\n",
              "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
              "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
              "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
              "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
              "      month     = {June},\n",
              "      year      = {2011},\n",
              "      address   = {Portland, Oregon, USA},\n",
              "      publisher = {Association for Computational Linguistics},\n",
              "      pages     = {142--150},\n",
              "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdrMkqL2g4tB",
        "outputId": "ecb59b26-241c-470c-ae1e-75f59cc0ef06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': <PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
              " 'train': <PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
              " 'unsupervised': <PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = dataset['train'], dataset['test']"
      ],
      "metadata": {
        "id": "PjqYl-lWhBfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXuxeT0WhfEK",
        "outputId": "7094bbbe-1199-4ba4-a7d0-fb855a55de1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvezYggdhjo6",
        "outputId": "e12b53b9-58fc-4611-d940-32db88829af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFpSf5MahkFc",
        "outputId": "ac52b77e-025e-482e-bb65-d413e9174a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in train_dataset:\n",
        "    print(sample[0].numpy())\n",
        "    print('\\n')\n",
        "    print(sample[1].numpy())\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTuazdkrhpBn",
        "outputId": "1afec786-336e-41de-9b01-a635556c4b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
            "\n",
            "\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "8VQJ1zvZhuLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "NaEawM9hhzDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "    print('texts: ', example.numpy()[:3])\n",
        "    print('\\n')\n",
        "    print('labels: ', label.numpy()[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGIK1784h1SX",
        "outputId": "9aa0c2aa-0428-4071-c111-10111ce3360c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texts:  [b'***SPOILERS*** ***SPOILERS*** When I saw a preview for this movie I thought it was going to be atleast a slightly admirable storyline. But as most superstation original movies I was left disapointed. This gullible family ends up driving through this \"deserted\" town to take a brake and find this video camera showing these people doing everything their donig and finds out they all eventually disappear, the family goes through all these mysterious stages and never discovers or displays what the heck is stalking them. Their are more gaps than I can count and they don\\'t explain anything that happens how or what. It ends where the family gets in a car accident and get posest or brainwashed or something( which is never explained). The next thing you know ur hoping they somehow find out how all it happened but it ends leaving you completely confused.'\n",
            " b\"Scott Menville is not Casey Kasem. That is the first, most important, and most disturbing thing about this attempt at re-imagining Scooby-Doo and company.<br /><br />Shaggy's voice is squeaky and does not sound anything like he has ever sounded in any of the previous incarnations of the Scooby shows. They've also changed the outfit and the classic mode of walking from the original.<br /><br />I'm not sure what they're on about yet with the villain angle, but it surely isn't following the formula used in any of the previous Scooby shows.<br /><br />And the animation style is very bizarre and distorted. I like it, but it's not real Scooby-Doo type animation. But the weird animation used for other WB shows grew on me; this might, too.<br /><br />It's worth a glance at -- once -- if you can handle the lack of proper Shaggy voice. That right there is enough to jar one out of enjoying the show properly. Besides, I am trying not to be an inflexible, nitpicking fan. Evolve or die, as the saying goes. We'll see how it looks after two more episodes -- by then I'll have formed a much more solid opinion.\"\n",
            " b'I understand this movie was made on a very low budget but that is no excuse for the monstrosity that is Grendel. Deathstalker, The Throne of Fire, Barbarian Queen, Conquest, the Invincible Barbarian were all done on shoestring budgets and poor special effects yet they still managed to create cult classics by adding some scantily clad women warriors and a good sense of humor. The primitive costumes, dark castles and beautiful Bulgarian landscape gave Grendel the potential to be a very good low budget sword and sorcery film, but the makers completely ruined this opportunity by using extremely poor CGI effects and colorless characters. Compare this film to Beowulf (1999). It may not be Citizen Kane but it is a good example of how an entertaining low budget sci-fi/ adventure movie can be made by using credible special effects and appealing characters.']\n",
            "\n",
            "\n",
            "labels:  [0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e = tf.keras.layers.experimental.preprocessing.TextVectorization()\n",
        "e.adapt([\n",
        "    \"I love samosas and jalebi\",\n",
        "    \"I love biking and yoga\",\n",
        "    \"I love tensorflow\"\n",
        "])"
      ],
      "metadata": {
        "id": "nasbWwLhh6RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyQIQ8eXh_Xd",
        "outputId": "65659333-a180-4c1a-d326-9705b2151ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'love',\n",
              " 'i',\n",
              " 'and',\n",
              " 'yoga',\n",
              " 'tensorflow',\n",
              " 'samosas',\n",
              " 'jalebi',\n",
              " 'biking']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e([\"I love pizza\"]).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp1W8KB5iCbI",
        "outputId": "8b4d8c11-4d5c-4afd-975b-c426e731d4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 2, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 1000\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))"
      ],
      "metadata": {
        "id": "V0lunSlwiFCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NLWUDWtiI9K",
        "outputId": "d503b92c-0cd6-4668-bd43-6ef4bcd736ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
              "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but',\n",
              "       'film', 'on', 'not', 'you', 'are'], dtype='<U14')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwSNDYF_iK5M",
        "outputId": "dcaf4649-95c7-437e-e8e2-5db915965bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=\n",
              "array([b'***SPOILERS*** ***SPOILERS*** When I saw a preview for this movie I thought it was going to be atleast a slightly admirable storyline. But as most superstation original movies I was left disapointed. This gullible family ends up driving through this \"deserted\" town to take a brake and find this video camera showing these people doing everything their donig and finds out they all eventually disappear, the family goes through all these mysterious stages and never discovers or displays what the heck is stalking them. Their are more gaps than I can count and they don\\'t explain anything that happens how or what. It ends where the family gets in a car accident and get posest or brainwashed or something( which is never explained). The next thing you know ur hoping they somehow find out how all it happened but it ends leaving you completely confused.',\n",
              "       b\"Scott Menville is not Casey Kasem. That is the first, most important, and most disturbing thing about this attempt at re-imagining Scooby-Doo and company.<br /><br />Shaggy's voice is squeaky and does not sound anything like he has ever sounded in any of the previous incarnations of the Scooby shows. They've also changed the outfit and the classic mode of walking from the original.<br /><br />I'm not sure what they're on about yet with the villain angle, but it surely isn't following the formula used in any of the previous Scooby shows.<br /><br />And the animation style is very bizarre and distorted. I like it, but it's not real Scooby-Doo type animation. But the weird animation used for other WB shows grew on me; this might, too.<br /><br />It's worth a glance at -- once -- if you can handle the lack of proper Shaggy voice. That right there is enough to jar one out of enjoying the show properly. Besides, I am trying not to be an inflexible, nitpicking fan. Evolve or die, as the saying goes. We'll see how it looks after two more episodes -- by then I'll have formed a much more solid opinion.\"],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_example = encoder(example)[:3].numpy()\n",
        "encoded_example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7teKJtgZiMWx",
        "outputId": "6aa9c3f2-20d4-454d-c135-525f0318dd44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1,   1,  51, ...,   0,   0,   0],\n",
              "       [  1,   1,   7, ...,   0,   0,   0],\n",
              "       [ 10, 373,  11, ...,   0,   0,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n in range(3):\n",
        "    print(\"Original: \", example[n].numpy())\n",
        "    print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW_8ajmPiOl7",
        "outputId": "7bddc373-3a29-437e-9792-654f05fd03a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  b'***SPOILERS*** ***SPOILERS*** When I saw a preview for this movie I thought it was going to be atleast a slightly admirable storyline. But as most superstation original movies I was left disapointed. This gullible family ends up driving through this \"deserted\" town to take a brake and find this video camera showing these people doing everything their donig and finds out they all eventually disappear, the family goes through all these mysterious stages and never discovers or displays what the heck is stalking them. Their are more gaps than I can count and they don\\'t explain anything that happens how or what. It ends where the family gets in a car accident and get posest or brainwashed or something( which is never explained). The next thing you know ur hoping they somehow find out how all it happened but it ends leaving you completely confused.'\n",
            "Round-trip:  [UNK] [UNK] when i saw a [UNK] for this movie i thought it was going to be [UNK] a [UNK] [UNK] storyline but as most [UNK] original movies i was left [UNK] this [UNK] family ends up [UNK] through this [UNK] town to take a [UNK] and find this video camera showing these people doing everything their [UNK] and finds out they all eventually [UNK] the family goes through all these [UNK] [UNK] and never [UNK] or [UNK] what the [UNK] is [UNK] them their are more [UNK] than i can [UNK] and they dont [UNK] anything that happens how or what it ends where the family gets in a car [UNK] and get [UNK] or [UNK] or something which is never [UNK] the next thing you know [UNK] [UNK] they somehow find out how all it happened but it ends [UNK] you completely [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
            "\n",
            "\n",
            "Original:  b\"Scott Menville is not Casey Kasem. That is the first, most important, and most disturbing thing about this attempt at re-imagining Scooby-Doo and company.<br /><br />Shaggy's voice is squeaky and does not sound anything like he has ever sounded in any of the previous incarnations of the Scooby shows. They've also changed the outfit and the classic mode of walking from the original.<br /><br />I'm not sure what they're on about yet with the villain angle, but it surely isn't following the formula used in any of the previous Scooby shows.<br /><br />And the animation style is very bizarre and distorted. I like it, but it's not real Scooby-Doo type animation. But the weird animation used for other WB shows grew on me; this might, too.<br /><br />It's worth a glance at -- once -- if you can handle the lack of proper Shaggy voice. That right there is enough to jar one out of enjoying the show properly. Besides, I am trying not to be an inflexible, nitpicking fan. Evolve or die, as the saying goes. We'll see how it looks after two more episodes -- by then I'll have formed a much more solid opinion.\"\n",
            "Round-trip:  [UNK] [UNK] is not [UNK] [UNK] that is the first most important and most [UNK] thing about this attempt at [UNK] [UNK] and [UNK] br [UNK] voice is [UNK] and does not sound anything like he has ever [UNK] in any of the previous [UNK] of the [UNK] shows [UNK] also [UNK] the [UNK] and the classic [UNK] of [UNK] from the [UNK] br im not sure what theyre on about yet with the [UNK] [UNK] but it [UNK] isnt [UNK] the [UNK] used in any of the previous [UNK] [UNK] br and the animation style is very [UNK] and [UNK] i like it but its not real [UNK] type animation but the weird animation used for other [UNK] shows [UNK] on me this might [UNK] br its worth a [UNK] at once if you can [UNK] the lack of [UNK] [UNK] voice that right there is enough to [UNK] one out of [UNK] the show [UNK] [UNK] i am trying not to be an [UNK] [UNK] fan [UNK] or die as the saying goes well see how it looks after two more episodes by then ill have [UNK] a much more [UNK] opinion                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
            "\n",
            "\n",
            "Original:  b'I understand this movie was made on a very low budget but that is no excuse for the monstrosity that is Grendel. Deathstalker, The Throne of Fire, Barbarian Queen, Conquest, the Invincible Barbarian were all done on shoestring budgets and poor special effects yet they still managed to create cult classics by adding some scantily clad women warriors and a good sense of humor. The primitive costumes, dark castles and beautiful Bulgarian landscape gave Grendel the potential to be a very good low budget sword and sorcery film, but the makers completely ruined this opportunity by using extremely poor CGI effects and colorless characters. Compare this film to Beowulf (1999). It may not be Citizen Kane but it is a good example of how an entertaining low budget sci-fi/ adventure movie can be made by using credible special effects and appealing characters.'\n",
            "Round-trip:  i understand this movie was made on a very low budget but that is no [UNK] for the [UNK] that is [UNK] [UNK] the [UNK] of fire [UNK] [UNK] [UNK] the [UNK] [UNK] were all done on [UNK] [UNK] and poor special effects yet they still [UNK] to create [UNK] [UNK] by [UNK] some [UNK] [UNK] women [UNK] and a good sense of humor the [UNK] [UNK] dark [UNK] and beautiful [UNK] [UNK] gave [UNK] the potential to be a very good low budget [UNK] and [UNK] film but the [UNK] completely [UNK] this [UNK] by using extremely poor [UNK] effects and [UNK] characters [UNK] this film to [UNK] [UNK] it may not be [UNK] [UNK] but it is a good example of how an entertaining low budget scifi [UNK] movie can be made by using [UNK] special effects and [UNK] characters                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "DB9h0w8iiTzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "sample_text = ('awesome movie, I loved it so much')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZYzajSWiaCc",
        "outputId": "c79facd6-f01c-44a1-e1c5-39819074177f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00274829]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WYpGgDKriflX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=10,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCBrfovXikPA",
        "outputId": "3182bf1a-f312-4cf1-d496-f5b992c15aa7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 107s 244ms/step - loss: 0.6562 - accuracy: 0.5591 - val_loss: 0.5358 - val_accuracy: 0.7089\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 92s 234ms/step - loss: 0.4252 - accuracy: 0.8018 - val_loss: 0.3771 - val_accuracy: 0.8359\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 93s 236ms/step - loss: 0.3536 - accuracy: 0.8441 - val_loss: 0.3454 - val_accuracy: 0.8510\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 93s 235ms/step - loss: 0.3264 - accuracy: 0.8582 - val_loss: 0.3293 - val_accuracy: 0.8516\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 93s 236ms/step - loss: 0.3164 - accuracy: 0.8621 - val_loss: 0.3274 - val_accuracy: 0.8609\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 91s 231ms/step - loss: 0.3098 - accuracy: 0.8656 - val_loss: 0.3273 - val_accuracy: 0.8474\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 92s 232ms/step - loss: 0.3039 - accuracy: 0.8693 - val_loss: 0.3190 - val_accuracy: 0.8599\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 92s 232ms/step - loss: 0.3054 - accuracy: 0.8672 - val_loss: 0.3520 - val_accuracy: 0.8562\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 93s 236ms/step - loss: 0.3014 - accuracy: 0.8686 - val_loss: 0.3174 - val_accuracy: 0.8641\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 94s 237ms/step - loss: 0.2980 - accuracy: 0.8722 - val_loss: 0.3184 - val_accuracy: 0.8630\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc10e6dafd0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check Sample Text Again - After Training**"
      ],
      "metadata": {
        "id": "HtpdmSFSpOwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions[0])"
      ],
      "metadata": {
        "id": "Z6fNkK84kDbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d47bb46-b4ca-41a9-8d09-4399f1909a8a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.2167441]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it is not near to zero and it is not Negetive at all."
      ],
      "metadata": {
        "id": "SNiSHy1_plY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text_for_test = ('Misery and Stand By Me were the best adaptations up until this one, now you can add Shawshank to that list.')\n",
        "\n",
        "\n",
        "predictions = model.predict(np.array([sample_text_for_test]))\n",
        "print(predictions[0])"
      ],
      "metadata": {
        "id": "2rYiP4BminKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d84458c9-bbe4-45da-b723-73383b653141"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.8862258]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LzDeJXp5oLTU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}